# SIREN ğŸ”Š

**S**emantic **I**nformation **R**epresentation for **E**fficient **N**eural-coding

A neural speech codec achieving **~68 bps** (bits per second) through advanced information factorization and residual finite scalar quantization.

## ğŸ¯ Features

- **Ultra-low bitrate**: ~68 bps (vs. 6000+ bps for Opus, 1500+ bps for Lyra)
- **Multi-speaker support**: Trained on English (LibriTTS) and Polish datasets
- **Information factorization**: Separates semantic content from speaker identity
- **Residual FSQ**: Finite Scalar Quantization with residual connections for better reconstruction
- **HiFi-GAN vocoder**: High-fidelity waveform synthesis

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    InformationFactorizer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ DistilHuBERTâ”‚ -> â”‚ Semantic     â”‚ -> â”‚ ResidualFSQ      â”‚   â”‚
â”‚  â”‚ Features    â”‚    â”‚ Branch       â”‚    â”‚ (2 stages)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚ Mel Spec    â”‚ -> â”‚ Acoustic     â”‚ (speaker conditioning)    â”‚
â”‚  â”‚             â”‚    â”‚ Branch       â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SpeechDecoder                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Semantic Upconv â”‚->â”‚ Cross-Modal   â”‚->â”‚ HiFi-GAN Decoder â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚ Fusion        â”‚  â”‚                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/Krabbens/SIREN.git
cd SIREN

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or: .venv\Scripts\activate  # Windows

# Install dependencies
pip install -e .
```

## ğŸš€ Quick Start

### Inference

```python
from ultra_low_bitrate_codec.scripts.inference_pipeline import CodecInference

# Load model
codec = CodecInference(checkpoint_path="checkpoints/model.pt")

# Encode audio to tokens
tokens = codec.encode("input.wav")
print(f"Bitrate: {codec.calculate_bitrate(tokens)} bps")

# Decode tokens back to audio
audio = codec.decode(tokens)
codec.save_audio(audio, "output.wav")
```

### Training

#### Single Speaker (LJSpeech)
```bash
# Download and prepare dataset
python scripts/download_libritts.py --dataset ljspeech

# Precompute DistilHuBERT features
python scripts/precompute_features.py --data_dir data/ljspeech

# Train
python ultra_low_bitrate_codec/scripts/train_fast.py \
    --config ultra_low_bitrate_codec/configs/improved_ljspeech.yaml
```

#### Multi-Speaker (LibriTTS + Polish)
```bash
# Prepare multi-speaker dataset
python ultra_low_bitrate_codec/scripts/prepare_multispeaker_dataset.py

# Train multi-speaker model
python train_multispeaker.py \
    --config ultra_low_bitrate_codec/configs/multispeaker.yaml
```

#### Resume Training
```bash
python resume_training.py --checkpoint checkpoints/step_10000.pt
python resume_multispeaker.py --checkpoint checkpoints_multispeaker/step_5000.pt
```

## ğŸ“ Project Structure

```
SIREN/
â”œâ”€â”€ ultra_low_bitrate_codec/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ encoder.py          # InformationFactorizer
â”‚   â”‚   â”œâ”€â”€ decoder.py          # SpeechDecoder with HiFi-GAN
â”‚   â”‚   â”œâ”€â”€ quantizers.py       # ResidualFSQ implementation
â”‚   â”‚   â”œâ”€â”€ vocoder.py          # HiFi-GAN vocoder
â”‚   â”‚   â”œâ”€â”€ discriminator.py    # Multi-period & multi-scale discriminators
â”‚   â”‚   â””â”€â”€ feature_extractor.py # DistilHuBERT wrapper
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ losses.py           # Multi-resolution STFT loss
â”‚   â”‚   â””â”€â”€ trainer.py          # Training loop
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train.py            # Basic training script
â”‚   â”‚   â”œâ”€â”€ train_fast.py       # Optimized training
â”‚   â”‚   â”œâ”€â”€ inference_pipeline.py # Inference utilities
â”‚   â”‚   â””â”€â”€ prepare_multispeaker_dataset.py
â”‚   â””â”€â”€ configs/
â”‚       â”œâ”€â”€ default.yaml
â”‚       â”œâ”€â”€ improved.yaml
â”‚       â””â”€â”€ multispeaker.yaml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_libritts.py    # Dataset download
â”‚   â”œâ”€â”€ precompute_features.py  # Feature extraction
â”‚   â””â”€â”€ setup_and_train_v2.sh   # Full setup script
â”œâ”€â”€ resume_training.py          # Resume single-speaker training
â”œâ”€â”€ resume_multispeaker.py      # Resume multi-speaker training
â””â”€â”€ train_multispeaker.py       # Multi-speaker training entry
```

## âš™ï¸ Configuration

Key parameters in config files:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `fsq_levels` | [8, 5, 5, 5] | FSQ quantization levels per dimension |
| `num_residual_stages` | 2 | Number of residual quantization stages |
| `semantic_dim` | 256 | Semantic embedding dimension |
| `decoder_channels` | 512 | Decoder hidden channels |
| `sample_rate` | 16000 | Audio sample rate |

## ğŸ“Š Results

| Model | Bitrate | MOS (estimated) |
|-------|---------|-----------------|
| Opus (reference) | 6000 bps | 4.0 |
| Lyra v2 | 3200 bps | 3.8 |
| **SIREN** | **68 bps** | 3.2* |

*Subjective evaluation pending

## ğŸ”¬ Technical Details

### Bitrate Calculation

```
Tokens per second = sample_rate / hop_length / temporal_reduction
                  = 16000 / 320 / 8 = 6.25 tokens/s

Bits per token = log2(prod(fsq_levels)) Ã— num_stages
               = log2(8Ã—5Ã—5Ã—5) Ã— 2 = 9.97 Ã— 2 â‰ˆ 20 bits

Bitrate = 6.25 Ã— (20 / 2) â‰ˆ 68 bps
```

### Loss Functions

- Multi-resolution STFT loss (reconstruction)
- Feature matching loss (GAN)
- Adversarial loss (multi-period + multi-scale discriminators)

## ğŸ“„ License

MIT License

## ğŸ™ Acknowledgments

- [DistilHuBERT](https://huggingface.co/ntu-spml/distilhubert) for semantic features
- HiFi-GAN architecture for high-quality synthesis
- FSQ from "Finite Scalar Quantization: VQ-VAE Made Simple"
